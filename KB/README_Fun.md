 # LangChain RAG пример на Node.js с PostgreSQL

Это приложение демонстрирует использование LangChain для реализации RAG (Retrieval Augmented Generation) на основе текстовых файлов с сохранением векторных представлений в PostgreSQL.

## Что такое RAG?

RAG (Retrieval Augmented Generation) - это подход, который объединяет два этапа:
1. **Retrieval (Извлечение)** - поиск релевантной информации из базы знаний
2. **Generation (Генерация)** - создание ответа с помощью языковой модели на основе найденной информации

Этот подход позволяет языковым моделям получать доступ к внешним знаниям, которые не входили в их обучающую выборку, и давать более точные и актуальные ответы.

## Функциональность

Приложение демонстрирует:
- Загрузку текстовых документов из директории
- Разделение текста на чанки
- Создание векторных представлений (эмбеддингов) для текстовых фрагментов
- Сохранение эмбеддингов в PostgreSQL
- Поиск релевантных фрагментов для заданного вопроса
- Генерацию ответа с использованием языковой модели и найденных фрагментов

## Требования

- Node.js (версия 16 или выше)
- API ключ OpenAI
- PostgreSQL с поддержкой типа `vector` (например, с расширением `pgvector`)
- Доступ к базе данных PostgreSQL (например, Supabase)

## Установка

1. Клонируйте репозиторий:
```bash
git clone https://github.com/yourusername/langchain-rag-example.git
cd langchain-rag-example
```

2. Установите зависимости:
```bash
npm install
```

3. Создайте файл `.env` на основе `.env.example`:
```bash
cp .env.example .env
```

4. Отредактируйте файл `.env` и добавьте ваш API ключ OpenAI и конфигурацию PostgreSQL:
```
OPENAI_API_KEY=your-openai-api-key-here
PG_USER=postgres.youruser
PG_HOST=your-postgresql-host
PG_DATABASE=postgres
PG_PASSWORD=your-password
PG_PORT=5432
PORT=3000
```

## Структура проекта

```
langchain-rag-example/
├── app.js          # Основной файл приложения
├── package.json    # Зависимости и скрипты
├── .env            # Переменные окружения
├── .env.example    # Пример файла переменных окружения
├── docs/           # Директория с текстовыми документами для RAG
│   ├── document1.txt
│   ├── document2.txt
│   └── document3.txt
└── public/         # Статические файлы для веб-интерфейса
    └── index.html  # Веб-интерфейс
```

## Настройка PostgreSQL

Для хранения векторных представлений используется таблица `file_vectors` в схеме `public`:

```sql
CREATE TABLE IF NOT EXISTS public.file_vectors (
  id UUID DEFAULT gen_random_uuid() NOT NULL PRIMARY KEY,
  file_url TEXT NOT NULL,
  embedding VECTOR(1536),
  created_at TIMESTAMP DEFAULT NOW()
);
```

Приложение автоматически создаст эту таблицу при первом запуске, если она еще не существует.

## Запуск

Для запуска приложения выполните:

```bash
npm start
```

Приложение будет доступно по адресу [http://localhost:3000](http://localhost:3000).

## Как это работает

1. При запуске приложение загружает текстовые документы из директории `/docs`
2. Документы разделяются на небольшие фрагменты (чанки)
3. Для каждого чанка создается векторное представление (эмбеддинг) с помощью OpenAI Embeddings API
4. Эмбеддинги сохраняются в:
   - Векторное хранилище в памяти для быстрого доступа
   - Таблицу `file_vectors` в PostgreSQL для постоянного хранения
5. Когда пользователь задает вопрос, происходит:
   - Создание эмбеддинга для вопроса
   - Поиск наиболее релевантных фрагментов текста в векторном хранилище
   - Отправка вопроса и найденных фрагментов в языковую модель (OpenAI)
   - Генерация ответа на основе вопроса и контекстных фрагментов

## Веб-интерфейс

Приложение предоставляет веб-интерфейс с двумя вкладками:

1. **Вопросы** - позволяет задавать вопросы по загруженным документам
2. **Документы** - отображает список документов и их статус векторизации:
   - Статус векторизации в памяти
   - Статус сохранения в PostgreSQL
   - Количество чанков для каждого документа
   - Возможность ручной векторизации документов

## Добавление своих документов

Для добавления собственных документов:

1. Поместите их в директорию `/docs` в формате `.txt`
2. Перезапустите приложение или используйте кнопку "Векторизовать" в веб-интерфейсе

## Настройка

Вы можете настроить различные параметры в файле `app.js`:

- Размер чанков и перекрытие: параметры `chunkSize` и `chunkOverlap`
- Модель LLM: параметр `modelName` в `ChatOpenAI`
- Температуру генерации: параметр `temperature` в `ChatOpenAI`
- Параметры подключения к PostgreSQL

## Возможные улучшения

1. Использование эмбеддингов из PostgreSQL для ответов на вопросы (сейчас используются только векторы в памяти)
2. Загрузка новых файлов через веб-интерфейс
3. Поддержка дополнительных форматов файлов (PDF, DOCX и т.д.)
4. Более подробная статистика по векторизации документов
5. Кеширование результатов запросов для повышения производительности
6. Использование semantic search в PostgreSQL с pgvector для поиска по схожести

## Лицензия

MIT