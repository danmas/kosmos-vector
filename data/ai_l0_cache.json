{
  "AIItem": {
    "l0_snippet": "class AIItem:\n\n    def __init__(self, id: str, type: str, contract: Dict[str, Any]):\n        self.id = id\n        self.type = type\n        self.contract = contract\n        self.l1_edges = []\n        self.l2 = None\n        self.embedding = None\n        self.file_path: Optional[str] = None\n        self.language: str = 'python'\n\n    def generate_l2(self, generator: Optional['L2Generator']=None):\n        if self.l2 is None:\n            if generator:\n                self.l2 = generator.generate_l2(self)\n            else:\n                self.l2 = {'purpose': self.contract.get('purpose', 'N/A'), 'uses': self.contract.get('uses', []), 'returns': self.contract.get('returns', 'N/A'), 'edge_cases': self.contract.get('edge_cases', 'N/A')}\n        return self.l2",
    "type": "class",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "AIItem.__init__": {
    "l0_snippet": "def __init__(self, id: str, type: str, contract: Dict[str, Any]):\n    self.id = id\n    self.type = type\n    self.contract = contract\n    self.l1_edges = []\n    self.l2 = None\n    self.embedding = None\n    self.file_path: Optional[str] = None\n    self.language: str = 'python'",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "AIItem.generate_l2": {
    "l0_snippet": "def generate_l2(self, generator: Optional['L2Generator']=None):\n    if self.l2 is None:\n        if generator:\n            self.l2 = generator.generate_l2(self)\n        else:\n            self.l2 = {'purpose': self.contract.get('purpose', 'N/A'), 'uses': self.contract.get('uses', []), 'returns': self.contract.get('returns', 'N/A'), 'edge_cases': self.contract.get('edge_cases', 'N/A')}\n    return self.l2",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "get_l0_snippet": {
    "l0_snippet": "def get_l0_snippet(item_id: str, max_len: int=None) -> str:\n    \"\"\"Получает L0 код из кэша по id.\"\"\"\n    cache = load_l0_cache()\n    entry = cache.get(item_id, {})\n    snippet = entry.get('l0_snippet', '')\n    if max_len and len(snippet) > max_len:\n        return snippet[:max_len] + '...'\n    return snippet",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "polish_l1_with_llm": {
    "l0_snippet": "def polish_l1_with_llm(item: AIItem, raw_edges: List[str], api_url: str, model: str, max_retries: int=3, dry_run: bool=False, llm_raw: bool=False) -> List[Dict[str, Any]]:\n    \"\"\"LLM-polish: Генерирует аннотированные edges с retry.\"\"\"\n    raw_str = ', '.join(raw_edges) if raw_edges else 'no raw edges'\n    l0_code = get_l0_snippet(item.id, 200)\n    prompt = f'Из кода [L0: {l0_code}] и raw edges [{raw_str}] сгенерируй аннотированные связи в JSON-массиве: [{{\"to\": \"target\", \"type\": \"calls\", \"reason\": \"кратко, если условие\"}}]. Макс 3 edges, только релевантные. Выводи ТОЛЬКО JSON-массив, без текста, без объяснений.'\n    if dry_run:\n        if raw_edges:\n            mock_content = json.dumps([{'to': raw_edges[0], 'type': 'calls', 'reason': 'fallback mock'}])\n        else:\n            mock_content = json.dumps([{'to': 'self', 'type': 'unknown', 'reason': 'no raw'}])\n        print(f'Mock content for {item.id}: {mock_content}')\n        return json.loads(mock_content)\n    payload = {'model': model, 'prompt': 'Ты парсер кода. Выводи только JSON-массив.', 'inputText': prompt}\n    for attempt in range(max_retries):\n        if llm_raw and (not dry_run):\n            curl_cmd = f\"\"\"curl -X POST \"{api_url}\" \\\\\\n  -H \"Content-Type: application/json\" \\\\\\n  -d '{json.dumps(payload)}'\"\"\"\n            print(f'CURL for {item.id} (attempt {attempt + 1}):')\n            print(curl_cmd)\n            print()\n        try:\n            import requests\n            response = requests.post(api_url, json=payload, timeout=10)\n            print(f'LLM response status for {item.id}: {response.status_code}')\n            response.raise_for_status()\n            data = response.json()\n            if data.get('success'):\n                content = data['content'].strip()\n                print(f'LLM content for {item.id}: {content[:100]}...')\n                if content.startswith('[') and content.endswith(']'):\n                    polished = json.loads(content)\n                    return polished if isinstance(polished, list) else []\n                else:\n                    print(f'Non-JSON content for {item.id}: {content}')\n            else:\n                print(f'No success in data for {item.id}: {data}')\n        except Exception as e:\n            print(f'LLM L1 API error for {item.id} (attempt {attempt + 1}): {e}')\n            if hasattr(e, 'response') and e.response is not None:\n                print(f'Full model response: {e.response.text}')\n            else:\n                print('No response text available')\n        if attempt < max_retries - 1:\n            print(f'Retry {attempt + 2}/{max_retries} in 2s...')\n            time.sleep(2)\n    if raw_edges:\n        return [{'to': e, 'type': 'unknown', 'reason': 'raw from AST'} for e in raw_edges]\n    else:\n        return [{'to': 'self', 'type': 'unknown', 'reason': 'LLM failed, no raw edges'}]",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "L2Generator": {
    "l0_snippet": "class L2Generator:\n    \"\"\"Генератор L2 c LLM и fallback.\"\"\"\n\n    def __init__(self, api_url: str='http://usa:3002/api/send-request', model: str='FAST', max_retries: int=3, dry_run: bool=False, llm_raw: bool=False):\n        self.api_url = api_url\n        self.model = model\n        self.max_retries = max_retries\n        self.dry_run = dry_run\n        self.llm_raw = llm_raw\n        self.use_llm = not dry_run\n\n    def generate_l2(self, item: AIItem) -> Dict[str, Any]:\n        if self.dry_run:\n            return self._fallback_l2(item)\n        prompt = self._build_prompt(item)\n        system_prompt = \"Ты анализатор кода. Отвечай ТОЛЬКО JSON: {'purpose': str, 'uses': list[str], 'returns': str, 'edge_cases': str}. Кратко (50-80 токенов).\"\n        for attempt in range(self.max_retries):\n            try:\n                import requests\n                import time\n                response = requests.post(self.api_url, json={'model': self.model, 'prompt': system_prompt, 'inputText': prompt}, timeout=10)\n                response.raise_for_status()\n                data = response.json()\n                if data.get('success'):\n                    content = data['content'].strip()\n                    if content.startswith('{') and content.endswith('}'):\n                        l2_data = json.loads(content)\n                        required = ['purpose', 'uses', 'returns', 'edge_cases']\n                        if all((k in l2_data for k in required)):\n                            print(f'L2 generated for {item.id}: {l2_data['purpose'][:50]}...')\n                            return l2_data\n            except Exception as e:\n                print(f'L2 API error for {item.id} (attempt {attempt + 1}): {e}')\n                if attempt < self.max_retries - 1:\n                    time.sleep(2)\n        print(f'L2 fallback for {item.id}')\n        return self._fallback_l2(item)\n\n    def generate_l2_batch(self, items: List[AIItem], batch_size: int=5) -> List[AIItem]:\n        \"\"\"Генерирует L2 для батча items через LLM или fallback.\"\"\"\n        if self.dry_run:\n            for item in items:\n                if item.l2 is None:\n                    item.l2 = self._fallback_l2(item)\n            return items\n        batches = [items[i:i + batch_size] for i in range(0, len(items), batch_size)]\n        for batch_idx, batch in enumerate(batches, 1):\n            print(f'Processing L2 batch {batch_idx}/{len(batches)} ({len(batch)} items)...')\n            batch_context = '\\n\\n'.join([f'Item {item.id}: {get_l0_snippet(item.id, 300)}' for item in batch])\n            prompt = f'Для следующих кодовых сниппетов сгенерируй L2-описания в JSON-массиве объектов. Каждый объект должен содержать: {{\"id\": \"item_id\", \"purpose\": \"краткое объяснение\", \"uses\": [\"зависимость1\", \"зависимость2\"], \"returns\": \"что возвращает\", \"edge_cases\": \"особенности\"}}.\\nКонтекст: {batch_context}\\nВыводи ТОЛЬКО JSON-массив, без текста.'\n            payload = {'model': self.model, 'prompt': 'Ты генератор L2 для RAG. Выводи только JSON-массив с объектами {id, purpose, uses, returns, edge_cases}.', 'inputText': prompt}\n            if self.llm_raw:\n                curl_cmd = f\"\"\"curl -X POST \"{self.api_url}\" \\\\\\n  -H \"Content-Type: application/json\" \\\\\\n  -d '{json.dumps(payload)}'\"\"\"\n                print(f'CURL for L2 batch {batch_idx}:')\n                print(curl_cmd)\n                print()\n            try:\n                import requests\n                response = requests.post(self.api_url, json=payload, timeout=30)\n                print(f'L2 batch {batch_idx} status: {response.status_code}')\n                response.raise_for_status()\n                data = response.json()\n                if data.get('success'):\n                    content = data['content'].strip()\n                    if content.startswith('[') and content.endswith(']'):\n                        l2_batch = json.loads(content)\n                        for item, l2_entry in zip(batch, l2_batch):\n                            if isinstance(l2_entry, dict) and l2_entry.get('id') == item.id:\n                                if all((k in l2_entry for k in ['purpose', 'uses', 'returns', 'edge_cases'])):\n                                    item.l2 = {'purpose': l2_entry['purpose'], 'uses': l2_entry.get('uses', []), 'returns': l2_entry.get('returns', 'N/A'), 'edge_cases': l2_entry.get('edge_cases', 'N/A')}\n                                else:\n                                    item.l2 = self._fallback_l2(item)\n                            else:\n                                item.l2 = self._fallback_l2(item)\n                        print(f'L2 batch {batch_idx} processed: {len(l2_batch)} entries.')\n                    else:\n                        print(f'Non-JSON L2 batch {batch_idx}: {content[:200]}...')\n                        for item in batch:\n                            if item.l2 is None:\n                                item.l2 = self._fallback_l2(item)\n                else:\n                    print(f'L2 batch {batch_idx} no success: {data}')\n                    for item in batch:\n                        if item.l2 is None:\n                            item.l2 = self._fallback_l2(item)\n            except Exception as e:\n                print(f'L2 batch {batch_idx} error: {e}')\n                for item in batch:\n                    if item.l2 is None:\n                        item.l2 = self._fallback_l2(item)\n            time.sleep(2)\n        return items\n\n    def _build_prompt(self, item: AIItem) -> str:\n        args_str = ', '.join(item.contract.get('args', [])) if 'args' in item.contract else 'N/A'\n        docstring = item.contract.get('docstring', 'No docstring')\n        calls = item.l1_edges if item.l1_edges else item.contract.get('uses', [])\n        snippet = get_l0_snippet(item.id, 300) or 'No code snippet available'\n        function_info = f'\\nID: {item.id}\\nType: {item.type}\\nArgs: {args_str}\\nDocstring: {docstring}\\nL0 Code: {snippet}...\\nL1 Calls/Edges: {calls}\\n'\n        prompt = f\"Проанализируй код и сгенерируй L2 в JSON:\\n- purpose: основная цель (1-2 предложения)\\n- uses: список (2-4) примеров использования/зависимостей\\n- returns: что возвращает (или 'None')\\n- edge_cases: 1-2 особенности/ошибки\\n\\n\\n\\n{function_info}\\n\\nВыводи ТОЛЬКО JSON.\"\n        return prompt\n\n    def _fallback_l2(self, item: AIItem) -> Dict[str, Any]:\n        \"\"\"Fallback: auto + docstring + snippet + edges для плотности.\"\"\"\n        contract = item.contract\n        purpose = contract.get('purpose', f'{item.type.capitalize()} {item.id}')\n        docstring = contract.get('docstring', 'No docstring')\n        args = contract.get('args', [])\n        returns = contract.get('returns', 'N/A')\n        full_snippet = get_l0_snippet(item.id) or ''\n        snippet = full_snippet.lower()\n        snippet_words = snippet.split()\n        uses = []\n        if item.l1_edges:\n            uses = [f'Called by {e['to']}' for e in item.l1_edges[:3]]\n        if not uses:\n            if 'self.' in snippet:\n                uses.append('Handles instance methods')\n            if 'def ' in snippet:\n                uses.append('Function definition')\n            if 'class ' in snippet:\n                uses.append('Class structure')\n        if not uses:\n            uses = ['In RAG pipeline']\n        edge_cases = []\n        if any((word in snippet for word in ['if', 'elif'])):\n            edge_cases.append('Conditional logic')\n        if 'try' in snippet or 'except' in snippet:\n            edge_cases.append('Error handling')\n        if 'for' in snippet or 'while' in snippet:\n            edge_cases.append('Iteration')\n        if not edge_cases:\n            edge_cases = ['N/A']\n        purpose += f' (Doc: {docstring[:50]}...)' if docstring != 'No docstring' else ''\n        if args:\n            purpose += f' Args: {', '.join(args)}'\n        purpose += f'. Snippet: {get_l0_snippet(item.id, 80)}'\n        return {'purpose': purpose, 'uses': uses, 'returns': returns, 'edge_cases': '; '.join(edge_cases)}",
    "type": "class",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "L2Generator.__init__": {
    "l0_snippet": "def __init__(self, api_url: str='http://usa:3002/api/send-request', model: str='FAST', max_retries: int=3, dry_run: bool=False, llm_raw: bool=False):\n    self.api_url = api_url\n    self.model = model\n    self.max_retries = max_retries\n    self.dry_run = dry_run\n    self.llm_raw = llm_raw\n    self.use_llm = not dry_run",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "L2Generator.generate_l2": {
    "l0_snippet": "def generate_l2(self, item: AIItem) -> Dict[str, Any]:\n    if self.dry_run:\n        return self._fallback_l2(item)\n    prompt = self._build_prompt(item)\n    system_prompt = \"Ты анализатор кода. Отвечай ТОЛЬКО JSON: {'purpose': str, 'uses': list[str], 'returns': str, 'edge_cases': str}. Кратко (50-80 токенов).\"\n    for attempt in range(self.max_retries):\n        try:\n            import requests\n            import time\n            response = requests.post(self.api_url, json={'model': self.model, 'prompt': system_prompt, 'inputText': prompt}, timeout=10)\n            response.raise_for_status()\n            data = response.json()\n            if data.get('success'):\n                content = data['content'].strip()\n                if content.startswith('{') and content.endswith('}'):\n                    l2_data = json.loads(content)\n                    required = ['purpose', 'uses', 'returns', 'edge_cases']\n                    if all((k in l2_data for k in required)):\n                        print(f'L2 generated for {item.id}: {l2_data['purpose'][:50]}...')\n                        return l2_data\n        except Exception as e:\n            print(f'L2 API error for {item.id} (attempt {attempt + 1}): {e}')\n            if attempt < self.max_retries - 1:\n                time.sleep(2)\n    print(f'L2 fallback for {item.id}')\n    return self._fallback_l2(item)",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "L2Generator.generate_l2_batch": {
    "l0_snippet": "def generate_l2_batch(self, items: List[AIItem], batch_size: int=5) -> List[AIItem]:\n    \"\"\"Генерирует L2 для батча items через LLM или fallback.\"\"\"\n    if self.dry_run:\n        for item in items:\n            if item.l2 is None:\n                item.l2 = self._fallback_l2(item)\n        return items\n    batches = [items[i:i + batch_size] for i in range(0, len(items), batch_size)]\n    for batch_idx, batch in enumerate(batches, 1):\n        print(f'Processing L2 batch {batch_idx}/{len(batches)} ({len(batch)} items)...')\n        batch_context = '\\n\\n'.join([f'Item {item.id}: {get_l0_snippet(item.id, 300)}' for item in batch])\n        prompt = f'Для следующих кодовых сниппетов сгенерируй L2-описания в JSON-массиве объектов. Каждый объект должен содержать: {{\"id\": \"item_id\", \"purpose\": \"краткое объяснение\", \"uses\": [\"зависимость1\", \"зависимость2\"], \"returns\": \"что возвращает\", \"edge_cases\": \"особенности\"}}.\\nКонтекст: {batch_context}\\nВыводи ТОЛЬКО JSON-массив, без текста.'\n        payload = {'model': self.model, 'prompt': 'Ты генератор L2 для RAG. Выводи только JSON-массив с объектами {id, purpose, uses, returns, edge_cases}.', 'inputText': prompt}\n        if self.llm_raw:\n            curl_cmd = f\"\"\"curl -X POST \"{self.api_url}\" \\\\\\n  -H \"Content-Type: application/json\" \\\\\\n  -d '{json.dumps(payload)}'\"\"\"\n            print(f'CURL for L2 batch {batch_idx}:')\n            print(curl_cmd)\n            print()\n        try:\n            import requests\n            response = requests.post(self.api_url, json=payload, timeout=30)\n            print(f'L2 batch {batch_idx} status: {response.status_code}')\n            response.raise_for_status()\n            data = response.json()\n            if data.get('success'):\n                content = data['content'].strip()\n                if content.startswith('[') and content.endswith(']'):\n                    l2_batch = json.loads(content)\n                    for item, l2_entry in zip(batch, l2_batch):\n                        if isinstance(l2_entry, dict) and l2_entry.get('id') == item.id:\n                            if all((k in l2_entry for k in ['purpose', 'uses', 'returns', 'edge_cases'])):\n                                item.l2 = {'purpose': l2_entry['purpose'], 'uses': l2_entry.get('uses', []), 'returns': l2_entry.get('returns', 'N/A'), 'edge_cases': l2_entry.get('edge_cases', 'N/A')}\n                            else:\n                                item.l2 = self._fallback_l2(item)\n                        else:\n                            item.l2 = self._fallback_l2(item)\n                    print(f'L2 batch {batch_idx} processed: {len(l2_batch)} entries.')\n                else:\n                    print(f'Non-JSON L2 batch {batch_idx}: {content[:200]}...')\n                    for item in batch:\n                        if item.l2 is None:\n                            item.l2 = self._fallback_l2(item)\n            else:\n                print(f'L2 batch {batch_idx} no success: {data}')\n                for item in batch:\n                    if item.l2 is None:\n                        item.l2 = self._fallback_l2(item)\n        except Exception as e:\n            print(f'L2 batch {batch_idx} error: {e}')\n            for item in batch:\n                if item.l2 is None:\n                    item.l2 = self._fallback_l2(item)\n        time.sleep(2)\n    return items",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "L2Generator._build_prompt": {
    "l0_snippet": "def _build_prompt(self, item: AIItem) -> str:\n    args_str = ', '.join(item.contract.get('args', [])) if 'args' in item.contract else 'N/A'\n    docstring = item.contract.get('docstring', 'No docstring')\n    calls = item.l1_edges if item.l1_edges else item.contract.get('uses', [])\n    snippet = get_l0_snippet(item.id, 300) or 'No code snippet available'\n    function_info = f'\\nID: {item.id}\\nType: {item.type}\\nArgs: {args_str}\\nDocstring: {docstring}\\nL0 Code: {snippet}...\\nL1 Calls/Edges: {calls}\\n'\n    prompt = f\"Проанализируй код и сгенерируй L2 в JSON:\\n- purpose: основная цель (1-2 предложения)\\n- uses: список (2-4) примеров использования/зависимостей\\n- returns: что возвращает (или 'None')\\n- edge_cases: 1-2 особенности/ошибки\\n\\n\\n\\n{function_info}\\n\\nВыводи ТОЛЬКО JSON.\"\n    return prompt",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "L2Generator._fallback_l2": {
    "l0_snippet": "def _fallback_l2(self, item: AIItem) -> Dict[str, Any]:\n    \"\"\"Fallback: auto + docstring + snippet + edges для плотности.\"\"\"\n    contract = item.contract\n    purpose = contract.get('purpose', f'{item.type.capitalize()} {item.id}')\n    docstring = contract.get('docstring', 'No docstring')\n    args = contract.get('args', [])\n    returns = contract.get('returns', 'N/A')\n    full_snippet = get_l0_snippet(item.id) or ''\n    snippet = full_snippet.lower()\n    snippet_words = snippet.split()\n    uses = []\n    if item.l1_edges:\n        uses = [f'Called by {e['to']}' for e in item.l1_edges[:3]]\n    if not uses:\n        if 'self.' in snippet:\n            uses.append('Handles instance methods')\n        if 'def ' in snippet:\n            uses.append('Function definition')\n        if 'class ' in snippet:\n            uses.append('Class structure')\n    if not uses:\n        uses = ['In RAG pipeline']\n    edge_cases = []\n    if any((word in snippet for word in ['if', 'elif'])):\n        edge_cases.append('Conditional logic')\n    if 'try' in snippet or 'except' in snippet:\n        edge_cases.append('Error handling')\n    if 'for' in snippet or 'while' in snippet:\n        edge_cases.append('Iteration')\n    if not edge_cases:\n        edge_cases = ['N/A']\n    purpose += f' (Doc: {docstring[:50]}...)' if docstring != 'No docstring' else ''\n    if args:\n        purpose += f' Args: {', '.join(args)}'\n    purpose += f'. Snippet: {get_l0_snippet(item.id, 80)}'\n    return {'purpose': purpose, 'uses': uses, 'returns': returns, 'edge_cases': '; '.join(edge_cases)}",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "EmbedRetriever": {
    "l0_snippet": "class EmbedRetriever:\n\n    def __init__(self, dim: int=384, model_name: str='intfloat/e5-small-v2', pickle_path: str='ai_embeddings.pkl'):\n        self.dim = dim\n        self.pickle_path = pickle_path\n        self.model_name = model_name\n        self.model = None\n        self.embeddings_dict = {}\n        self.texts = {}\n        self.loaded = False\n        self._try_load()\n\n    def add_items(self, ai_items: Dict[str, AIItem], generator: Optional[L2Generator]=None, l2_batch_size: int=5):\n        old_len = len(self.embeddings_dict)\n        for iid, item in ai_items.items():\n            self.texts[iid] = item.contract['purpose']\n        new_items = [iid for iid in self.texts if iid not in self.embeddings_dict]\n        if new_items:\n            print(f'Updating embeddings for {len(new_items)} new items...')\n            text_list = [self.texts[iid] for iid in new_items]\n            embeddings = self._encode(text_list)\n            for i, iid in enumerate(new_items):\n                self.embeddings_dict[iid] = embeddings[i]\n            self._save_pickle()\n            print('Updated and saved.')\n        elif not self.loaded:\n            self._generate_if_needed()\n        if generator:\n            pending = [ai_items[iid] for iid in ai_items if ai_items[iid].l2 is None]\n            if pending:\n                generator.generate_l2_batch(pending, batch_size=l2_batch_size)\n\n    def _try_load(self):\n        try:\n            with open(self.pickle_path, 'rb') as f:\n                data = pickle.load(f)\n                self.texts = data['texts']\n                self.embeddings_dict = {tid: np.array(vec) for tid, vec in zip(data['ids'], data['embeddings'])}\n            print(f'Loaded {len(self.embeddings_dict)} embeddings from {self.pickle_path}')\n            self.loaded = True\n        except FileNotFoundError:\n            print('No pickle found.')\n            self.loaded = False\n\n    def _generate_if_needed(self):\n        if self.loaded or not self.texts:\n            return\n        print('Generating embeddings...')\n        text_list = list(self.texts.values())\n        embeddings = self._encode(text_list)\n        ids_list = list(self.texts.keys())\n        for i, iid in enumerate(ids_list):\n            self.embeddings_dict[iid] = embeddings[i]\n        self._save_pickle()\n        print('Generated and saved.')\n        self.loaded = True\n\n    def _encode(self, texts: List[str]) -> np.ndarray:\n        global REAL_MODEL\n        if REAL_MODEL and self.model is None:\n            self.model = SentenceTransformer(self.model_name)\n            print(f'Loaded model: {self.model_name}')\n        if REAL_MODEL and self.model:\n            prefixed_texts = ['passage: ' + t for t in texts]\n            return self.model.encode(prefixed_texts)\n        else:\n            np.random.seed(42)\n            return np.random.normal(0, 1, (len(texts), self.dim)).astype(np.float32)\n\n    def _save_pickle(self):\n        data = {'ids': list(self.embeddings_dict.keys()), 'texts': self.texts, 'embeddings': np.stack([vec for vec in self.embeddings_dict.values()])}\n        with open(self.pickle_path, 'wb') as f:\n            pickle.dump(data, f)\n\n    def encode_query(self, query: str) -> np.ndarray:\n        if REAL_MODEL and self.model:\n            return self.model.encode(['query: ' + query])[0]\n        else:\n            np.random.seed(42)\n            return np.random.normal(0, 1, self.dim).astype(np.float32)\n\n    def get_similarities(self, query_emb: np.ndarray, item_ids: List[str]) -> np.ndarray:\n        from sklearn.metrics.pairwise import cosine_similarity\n        existing_ids = [iid for iid in item_ids if iid in self.embeddings_dict]\n        if not existing_ids:\n            return np.zeros(len(item_ids))\n        vecs = np.stack([self.embeddings_dict[iid] for iid in existing_ids])\n        sims = cosine_similarity(query_emb.reshape(1, -1), vecs).flatten()\n        full_sims = np.zeros(len(item_ids))\n        for i, iid in enumerate(item_ids):\n            if iid in existing_ids:\n                full_sims[i] = sims[existing_ids.index(iid)]\n        return full_sims",
    "type": "class",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "EmbedRetriever.__init__": {
    "l0_snippet": "def __init__(self, dim: int=384, model_name: str='intfloat/e5-small-v2', pickle_path: str='ai_embeddings.pkl'):\n    self.dim = dim\n    self.pickle_path = pickle_path\n    self.model_name = model_name\n    self.model = None\n    self.embeddings_dict = {}\n    self.texts = {}\n    self.loaded = False\n    self._try_load()",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "EmbedRetriever.add_items": {
    "l0_snippet": "def add_items(self, ai_items: Dict[str, AIItem], generator: Optional[L2Generator]=None, l2_batch_size: int=5):\n    old_len = len(self.embeddings_dict)\n    for iid, item in ai_items.items():\n        self.texts[iid] = item.contract['purpose']\n    new_items = [iid for iid in self.texts if iid not in self.embeddings_dict]\n    if new_items:\n        print(f'Updating embeddings for {len(new_items)} new items...')\n        text_list = [self.texts[iid] for iid in new_items]\n        embeddings = self._encode(text_list)\n        for i, iid in enumerate(new_items):\n            self.embeddings_dict[iid] = embeddings[i]\n        self._save_pickle()\n        print('Updated and saved.')\n    elif not self.loaded:\n        self._generate_if_needed()\n    if generator:\n        pending = [ai_items[iid] for iid in ai_items if ai_items[iid].l2 is None]\n        if pending:\n            generator.generate_l2_batch(pending, batch_size=l2_batch_size)",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "EmbedRetriever._try_load": {
    "l0_snippet": "def _try_load(self):\n    try:\n        with open(self.pickle_path, 'rb') as f:\n            data = pickle.load(f)\n            self.texts = data['texts']\n            self.embeddings_dict = {tid: np.array(vec) for tid, vec in zip(data['ids'], data['embeddings'])}\n        print(f'Loaded {len(self.embeddings_dict)} embeddings from {self.pickle_path}')\n        self.loaded = True\n    except FileNotFoundError:\n        print('No pickle found.')\n        self.loaded = False",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "EmbedRetriever._generate_if_needed": {
    "l0_snippet": "def _generate_if_needed(self):\n    if self.loaded or not self.texts:\n        return\n    print('Generating embeddings...')\n    text_list = list(self.texts.values())\n    embeddings = self._encode(text_list)\n    ids_list = list(self.texts.keys())\n    for i, iid in enumerate(ids_list):\n        self.embeddings_dict[iid] = embeddings[i]\n    self._save_pickle()\n    print('Generated and saved.')\n    self.loaded = True",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "EmbedRetriever._encode": {
    "l0_snippet": "def _encode(self, texts: List[str]) -> np.ndarray:\n    global REAL_MODEL\n    if REAL_MODEL and self.model is None:\n        self.model = SentenceTransformer(self.model_name)\n        print(f'Loaded model: {self.model_name}')\n    if REAL_MODEL and self.model:\n        prefixed_texts = ['passage: ' + t for t in texts]\n        return self.model.encode(prefixed_texts)\n    else:\n        np.random.seed(42)\n        return np.random.normal(0, 1, (len(texts), self.dim)).astype(np.float32)",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "EmbedRetriever._save_pickle": {
    "l0_snippet": "def _save_pickle(self):\n    data = {'ids': list(self.embeddings_dict.keys()), 'texts': self.texts, 'embeddings': np.stack([vec for vec in self.embeddings_dict.values()])}\n    with open(self.pickle_path, 'wb') as f:\n        pickle.dump(data, f)",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "EmbedRetriever.encode_query": {
    "l0_snippet": "def encode_query(self, query: str) -> np.ndarray:\n    if REAL_MODEL and self.model:\n        return self.model.encode(['query: ' + query])[0]\n    else:\n        np.random.seed(42)\n        return np.random.normal(0, 1, self.dim).astype(np.float32)",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "EmbedRetriever.get_similarities": {
    "l0_snippet": "def get_similarities(self, query_emb: np.ndarray, item_ids: List[str]) -> np.ndarray:\n    from sklearn.metrics.pairwise import cosine_similarity\n    existing_ids = [iid for iid in item_ids if iid in self.embeddings_dict]\n    if not existing_ids:\n        return np.zeros(len(item_ids))\n    vecs = np.stack([self.embeddings_dict[iid] for iid in existing_ids])\n    sims = cosine_similarity(query_emb.reshape(1, -1), vecs).flatten()\n    full_sims = np.zeros(len(item_ids))\n    for i, iid in enumerate(item_ids):\n        if iid in existing_ids:\n            full_sims[i] = sims[existing_ids.index(iid)]\n    return full_sims",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "build_graph": {
    "l0_snippet": "def build_graph(ai_items: Dict[str, AIItem], calls_dict: Dict[str, List[str]], save_cache: bool=False) -> nx.DiGraph:\n    G = nx.DiGraph()\n    for item_id, item in ai_items.items():\n        G.add_node(item_id, type=item.type, weight=item.contract.get('weight', 1.0))\n    for caller, called_list in calls_dict.items():\n        for called in called_list:\n            called_id = called.split(' (')[0]\n            if called_id in ai_items:\n                edge_type = 'calls' if not ' (' in called else called.split(' (')[1].rstrip(')')\n                G.add_edge(caller, called_id, type=edge_type, weight=0.95)\n    for item_id, item in ai_items.items():\n        neighbors = list(G.successors(item_id)) + list(G.predecessors(item_id))\n        item.l1_edges = [{'to': n, 'type': G[item_id][n].get('type', 'unknown') if n in G.successors(item_id) else G[n][item_id].get('type', 'unknown')} for n in set(neighbors)]\n    return G",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "retrieve_hybrid": {
    "l0_snippet": "def retrieve_hybrid(query: str, ai_items: Dict[str, AIItem], G: nx.DiGraph, retriever: EmbedRetriever, top_k: int=4) -> List[AIItem]:\n    \"\"\"Гибридный поиск: векторный + граф\"\"\"\n    item_ids = list(ai_items.keys())\n    keyword_matched = [iid for iid in item_ids if any((pattern in query.lower() for pattern in ai_items[iid].contract.get('query_patterns', [])))]\n    query_emb = retriever.encode_query(query)\n    sims = retriever.get_similarities(query_emb, item_ids)\n    scores = sims.copy()\n    for km in keyword_matched:\n        idx = item_ids.index(km)\n        scores[idx] += 0.5\n    top_indices = np.argsort(scores)[-top_k:]\n    matched = [ai_items[item_ids[i]] for i in top_indices]\n    if matched:\n        start = matched[0].id\n        neighbors = [n for n in nx.descendants(G, start) if n in ai_items]\n        for n in neighbors[:top_k - len(matched)]:\n            matched.append(ai_items[n])\n    return list(set(matched))[:top_k]",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "parse_self_to_ai_items": {
    "l0_snippet": "def parse_self_to_ai_items(auto_l1: bool=True, llm_l1: bool=False, api_url: str='http://usa:3002/api/send-request') -> tuple[Dict[str, AIItem], Dict[str, List[str]]]:\n    import ast\n    with open(__file__, 'r', encoding='utf-8-sig') as f:\n        code = f.read()\n    tree = ast.parse(code)\n\n    class ImprovedCodeParser(ast.NodeVisitor):\n\n        def __init__(self):\n            self.items = []\n            self.current_class = None\n            self.current_func = None\n            self.calls_dict = {}\n            self.assigns_dict = {}\n            self.imports_dict = {}\n            self.built_ins = ['print', 'len', 'str', 'list', 'dict', 'np', 'json', 'pickle', 'open', 'np.random', 'ast.parse', 'cosine_similarity', 'np.stack', 'torch', 'sklearn', 'networkx', 'SentenceTransformer']\n\n        def visit_ClassDef(self, node):\n            self.current_class = node.name\n            self.calls_dict[self.current_class] = []\n            self.assigns_dict[self.current_class] = []\n            self.imports_dict[self.current_class] = []\n            snippet = ast.unparse(node)\n            if node.body:\n                method_ids = [stmt.name for stmt in node.body if isinstance(stmt, ast.FunctionDef)]\n                for m in method_ids:\n                    self.calls_dict[self.current_class].append(f'{self.current_class}.{m} (contains)')\n            purpose = f'Класс {node.name} в прототипе RAG-системы.'\n            docstring = ast.get_docstring(node) or 'N/A'\n            contract = {'purpose': purpose, 'query_patterns': [node.name.lower()], 'weight': 2.0, 'uses': [], 'returns': 'instance', 'edge_cases': 'N/A', 'docstring': docstring, 'args': []}\n            item_id = node.name\n            merge_l0_cache({item_id: {'l0_snippet': snippet, 'type': 'class', 'file_path': __file__, 'source': 'AST'}})\n            self.items.append({'id': item_id, 'type': 'class', 'contract': contract})\n            self.generic_visit(node)\n            self.current_class = None\n\n        def visit_FunctionDef(self, node):\n            self.current_func = node.name\n            snippet = ast.unparse(node)\n            purpose = f'Функция {node.name} в прототипе RAG.'\n            docstring = ast.get_docstring(node) or 'N/A'\n            args = [arg.arg for arg in node.args.args] if isinstance(node.args, ast.arguments) else []\n            contract = {'purpose': purpose, 'query_patterns': [node.name], 'weight': 1.5, 'uses': [], 'returns': 'result', 'edge_cases': 'N/A', 'docstring': docstring, 'args': args}\n            item_id = f'{self.current_class}.{node.name}' if self.current_class else node.name\n            merge_l0_cache({item_id: {'l0_snippet': snippet, 'type': 'function', 'file_path': __file__, 'source': 'AST'}})\n            self.items.append({'id': item_id, 'type': 'function', 'contract': contract})\n            caller_id = item_id\n            self.calls_dict[caller_id] = []\n            self.assigns_dict[caller_id] = []\n            self.imports_dict[caller_id] = []\n            self.generic_visit(node)\n            self.current_func = None\n\n        def visit_Call(self, node):\n            called = None\n            if isinstance(node.func, ast.Attribute):\n                if isinstance(node.func.value, ast.Name) and node.func.value.id == 'self':\n                    called = node.func.attr\n            elif isinstance(node.func, ast.Name):\n                called = node.func.id\n            if called and self.current_func is not None:\n                caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_func or 'global'\n                called_id = f'{self.current_class}.{called}' if self.current_class else called\n                if called_id not in self.built_ins and called_id not in self.calls_dict.get(caller_id, []):\n                    self.calls_dict[caller_id] = self.calls_dict.get(caller_id, []) + [called_id]\n            self.generic_visit(node)\n\n        def visit_Assign(self, node):\n            if self.current_func:\n                caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_func or 'global'\n                if isinstance(node.value, ast.Call):\n                    called = node.value.func.id if isinstance(node.value.func, ast.Name) else node.value.func.attr if isinstance(node.value.func, ast.Attribute) else None\n                    if called and called not in self.built_ins:\n                        called_id = f'{self.current_class}.{called}' if self.current_class else called\n                        if called_id not in self.assigns_dict.get(caller_id, []):\n                            self.assigns_dict[caller_id] = self.assigns_dict.get(caller_id, []) + [called_id]\n            self.generic_visit(node)\n\n        def visit_Import(self, node):\n            if self.current_func or self.current_class:\n                caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_class or 'global'\n                for alias in node.names:\n                    lib = alias.name.split('.')[0]\n                    if lib not in self.built_ins:\n                        lib_id = f'lib.{lib}'\n                        if lib_id not in self.imports_dict.get(caller_id, []):\n                            self.imports_dict[caller_id] = self.imports_dict.get(caller_id, []) + [lib_id]\n            self.generic_visit(node)\n\n        def visit_ImportFrom(self, node):\n            if self.current_func or self.current_class:\n                caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_class or 'global'\n                lib = node.module.split('.')[0] if node.module else 'unknown'\n                for alias in node.names:\n                    imported = alias.name\n                    lib_id = f'lib.{lib}.{imported}'\n                    if lib_id not in self.built_ins and lib_id not in self.imports_dict.get(caller_id, []):\n                        self.imports_dict[caller_id] = self.imports_dict.get(caller_id, []) + [lib_id]\n            self.generic_visit(node)\n    parser = ImprovedCodeParser()\n    parser.visit(tree)\n    ai_items = {}\n    for item_data in parser.items:\n        ai_items[item_data['id']] = AIItem(**item_data)\n    calls_dict = parser.calls_dict\n    for k, v in parser.assigns_dict.items():\n        calls_dict.setdefault(k, []).extend([f'{x} (assign)' for x in v])\n    for k, v in parser.imports_dict.items():\n        calls_dict.setdefault(k, []).extend([f'{x} (import)' for x in v])\n    print(f'Parsed calls example: {list(calls_dict.items())[:3]}')\n    return (ai_items, calls_dict)",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "ImprovedCodeParser": {
    "l0_snippet": "class ImprovedCodeParser(ast.NodeVisitor):\n\n    def __init__(self):\n        self.items = []\n        self.current_class = None\n        self.current_func = None\n        self.calls_dict = {}\n        self.assigns_dict = {}\n        self.imports_dict = {}\n        self.built_ins = ['print', 'len', 'str', 'list', 'dict', 'np', 'json', 'pickle', 'open', 'np.random', 'ast.parse', 'cosine_similarity', 'np.stack', 'torch', 'sklearn', 'networkx', 'SentenceTransformer']\n\n    def visit_ClassDef(self, node):\n        self.current_class = node.name\n        self.calls_dict[self.current_class] = []\n        self.assigns_dict[self.current_class] = []\n        self.imports_dict[self.current_class] = []\n        snippet = ast.unparse(node)\n        if node.body:\n            method_ids = [stmt.name for stmt in node.body if isinstance(stmt, ast.FunctionDef)]\n            for m in method_ids:\n                self.calls_dict[self.current_class].append(f'{self.current_class}.{m} (contains)')\n        purpose = f'Класс {node.name} в прототипе RAG-системы.'\n        docstring = ast.get_docstring(node) or 'N/A'\n        contract = {'purpose': purpose, 'query_patterns': [node.name.lower()], 'weight': 2.0, 'uses': [], 'returns': 'instance', 'edge_cases': 'N/A', 'docstring': docstring, 'args': []}\n        item_id = node.name\n        merge_l0_cache({item_id: {'l0_snippet': snippet, 'type': 'class', 'file_path': __file__, 'source': 'AST'}})\n        self.items.append({'id': item_id, 'type': 'class', 'contract': contract})\n        self.generic_visit(node)\n        self.current_class = None\n\n    def visit_FunctionDef(self, node):\n        self.current_func = node.name\n        snippet = ast.unparse(node)\n        purpose = f'Функция {node.name} в прототипе RAG.'\n        docstring = ast.get_docstring(node) or 'N/A'\n        args = [arg.arg for arg in node.args.args] if isinstance(node.args, ast.arguments) else []\n        contract = {'purpose': purpose, 'query_patterns': [node.name], 'weight': 1.5, 'uses': [], 'returns': 'result', 'edge_cases': 'N/A', 'docstring': docstring, 'args': args}\n        item_id = f'{self.current_class}.{node.name}' if self.current_class else node.name\n        merge_l0_cache({item_id: {'l0_snippet': snippet, 'type': 'function', 'file_path': __file__, 'source': 'AST'}})\n        self.items.append({'id': item_id, 'type': 'function', 'contract': contract})\n        caller_id = item_id\n        self.calls_dict[caller_id] = []\n        self.assigns_dict[caller_id] = []\n        self.imports_dict[caller_id] = []\n        self.generic_visit(node)\n        self.current_func = None\n\n    def visit_Call(self, node):\n        called = None\n        if isinstance(node.func, ast.Attribute):\n            if isinstance(node.func.value, ast.Name) and node.func.value.id == 'self':\n                called = node.func.attr\n        elif isinstance(node.func, ast.Name):\n            called = node.func.id\n        if called and self.current_func is not None:\n            caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_func or 'global'\n            called_id = f'{self.current_class}.{called}' if self.current_class else called\n            if called_id not in self.built_ins and called_id not in self.calls_dict.get(caller_id, []):\n                self.calls_dict[caller_id] = self.calls_dict.get(caller_id, []) + [called_id]\n        self.generic_visit(node)\n\n    def visit_Assign(self, node):\n        if self.current_func:\n            caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_func or 'global'\n            if isinstance(node.value, ast.Call):\n                called = node.value.func.id if isinstance(node.value.func, ast.Name) else node.value.func.attr if isinstance(node.value.func, ast.Attribute) else None\n                if called and called not in self.built_ins:\n                    called_id = f'{self.current_class}.{called}' if self.current_class else called\n                    if called_id not in self.assigns_dict.get(caller_id, []):\n                        self.assigns_dict[caller_id] = self.assigns_dict.get(caller_id, []) + [called_id]\n        self.generic_visit(node)\n\n    def visit_Import(self, node):\n        if self.current_func or self.current_class:\n            caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_class or 'global'\n            for alias in node.names:\n                lib = alias.name.split('.')[0]\n                if lib not in self.built_ins:\n                    lib_id = f'lib.{lib}'\n                    if lib_id not in self.imports_dict.get(caller_id, []):\n                        self.imports_dict[caller_id] = self.imports_dict.get(caller_id, []) + [lib_id]\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node):\n        if self.current_func or self.current_class:\n            caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_class or 'global'\n            lib = node.module.split('.')[0] if node.module else 'unknown'\n            for alias in node.names:\n                imported = alias.name\n                lib_id = f'lib.{lib}.{imported}'\n                if lib_id not in self.built_ins and lib_id not in self.imports_dict.get(caller_id, []):\n                    self.imports_dict[caller_id] = self.imports_dict.get(caller_id, []) + [lib_id]\n        self.generic_visit(node)",
    "type": "class",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "ImprovedCodeParser.__init__": {
    "l0_snippet": "def __init__(self):\n    self.items = []\n    self.current_class = None\n    self.current_func = None\n    self.calls_dict = {}\n    self.assigns_dict = {}\n    self.imports_dict = {}\n    self.built_ins = ['print', 'len', 'str', 'list', 'dict', 'np', 'json', 'pickle', 'open', 'np.random', 'ast.parse', 'cosine_similarity', 'np.stack', 'torch', 'sklearn', 'networkx', 'SentenceTransformer']",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "ImprovedCodeParser.visit_ClassDef": {
    "l0_snippet": "def visit_ClassDef(self, node):\n    self.current_class = node.name\n    self.calls_dict[self.current_class] = []\n    self.assigns_dict[self.current_class] = []\n    self.imports_dict[self.current_class] = []\n    snippet = ast.unparse(node)\n    if node.body:\n        method_ids = [stmt.name for stmt in node.body if isinstance(stmt, ast.FunctionDef)]\n        for m in method_ids:\n            self.calls_dict[self.current_class].append(f'{self.current_class}.{m} (contains)')\n    purpose = f'Класс {node.name} в прототипе RAG-системы.'\n    docstring = ast.get_docstring(node) or 'N/A'\n    contract = {'purpose': purpose, 'query_patterns': [node.name.lower()], 'weight': 2.0, 'uses': [], 'returns': 'instance', 'edge_cases': 'N/A', 'docstring': docstring, 'args': []}\n    item_id = node.name\n    merge_l0_cache({item_id: {'l0_snippet': snippet, 'type': 'class', 'file_path': __file__, 'source': 'AST'}})\n    self.items.append({'id': item_id, 'type': 'class', 'contract': contract})\n    self.generic_visit(node)\n    self.current_class = None",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "ImprovedCodeParser.visit_FunctionDef": {
    "l0_snippet": "def visit_FunctionDef(self, node):\n    self.current_func = node.name\n    snippet = ast.unparse(node)\n    purpose = f'Функция {node.name} в прототипе RAG.'\n    docstring = ast.get_docstring(node) or 'N/A'\n    args = [arg.arg for arg in node.args.args] if isinstance(node.args, ast.arguments) else []\n    contract = {'purpose': purpose, 'query_patterns': [node.name], 'weight': 1.5, 'uses': [], 'returns': 'result', 'edge_cases': 'N/A', 'docstring': docstring, 'args': args}\n    item_id = f'{self.current_class}.{node.name}' if self.current_class else node.name\n    merge_l0_cache({item_id: {'l0_snippet': snippet, 'type': 'function', 'file_path': __file__, 'source': 'AST'}})\n    self.items.append({'id': item_id, 'type': 'function', 'contract': contract})\n    caller_id = item_id\n    self.calls_dict[caller_id] = []\n    self.assigns_dict[caller_id] = []\n    self.imports_dict[caller_id] = []\n    self.generic_visit(node)\n    self.current_func = None",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "ImprovedCodeParser.visit_Call": {
    "l0_snippet": "def visit_Call(self, node):\n    called = None\n    if isinstance(node.func, ast.Attribute):\n        if isinstance(node.func.value, ast.Name) and node.func.value.id == 'self':\n            called = node.func.attr\n    elif isinstance(node.func, ast.Name):\n        called = node.func.id\n    if called and self.current_func is not None:\n        caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_func or 'global'\n        called_id = f'{self.current_class}.{called}' if self.current_class else called\n        if called_id not in self.built_ins and called_id not in self.calls_dict.get(caller_id, []):\n            self.calls_dict[caller_id] = self.calls_dict.get(caller_id, []) + [called_id]\n    self.generic_visit(node)",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "ImprovedCodeParser.visit_Assign": {
    "l0_snippet": "def visit_Assign(self, node):\n    if self.current_func:\n        caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_func or 'global'\n        if isinstance(node.value, ast.Call):\n            called = node.value.func.id if isinstance(node.value.func, ast.Name) else node.value.func.attr if isinstance(node.value.func, ast.Attribute) else None\n            if called and called not in self.built_ins:\n                called_id = f'{self.current_class}.{called}' if self.current_class else called\n                if called_id not in self.assigns_dict.get(caller_id, []):\n                    self.assigns_dict[caller_id] = self.assigns_dict.get(caller_id, []) + [called_id]\n    self.generic_visit(node)",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "ImprovedCodeParser.visit_Import": {
    "l0_snippet": "def visit_Import(self, node):\n    if self.current_func or self.current_class:\n        caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_class or 'global'\n        for alias in node.names:\n            lib = alias.name.split('.')[0]\n            if lib not in self.built_ins:\n                lib_id = f'lib.{lib}'\n                if lib_id not in self.imports_dict.get(caller_id, []):\n                    self.imports_dict[caller_id] = self.imports_dict.get(caller_id, []) + [lib_id]\n    self.generic_visit(node)",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "ImprovedCodeParser.visit_ImportFrom": {
    "l0_snippet": "def visit_ImportFrom(self, node):\n    if self.current_func or self.current_class:\n        caller_id = f'{self.current_class}.{self.current_func}' if self.current_class and self.current_func else self.current_class or 'global'\n        lib = node.module.split('.')[0] if node.module else 'unknown'\n        for alias in node.names:\n            imported = alias.name\n            lib_id = f'lib.{lib}.{imported}'\n            if lib_id not in self.built_ins and lib_id not in self.imports_dict.get(caller_id, []):\n                self.imports_dict[caller_id] = self.imports_dict.get(caller_id, []) + [lib_id]\n    self.generic_visit(node)",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  },
  "init_engine": {
    "l0_snippet": "def init_engine(use_llm_l1: bool=False, load_cache: bool=True, save_cache: bool=True, api_url: str='http://usa:3002/api/send-request', model: str='FAST', llm_raw: bool=False):\n    \"\"\"Инициализация RAG движка\"\"\"\n    global ai_items, G, retriever, l2_generator\n    print('Инициализация Kosmos Vector RAG Engine...')\n    ai_items_data, calls_dict = parse_self_to_ai_items()\n    ai_items.clear()\n    ai_items.update(ai_items_data)\n    for item in ai_items.values():\n        item.file_path = __file__\n        item.language = 'python'\n    l1_cache_loaded_ids = set()\n    if load_cache and l1_cache_path.exists():\n        print('Загрузка L1 кэша...')\n        l1_cache = load_l1_cache(str(l1_cache_path))\n        for item_id, item in ai_items.items():\n            if item_id in l1_cache:\n                cache_entry = l1_cache[item_id]\n                try:\n                    item.l1_edges = json.loads(cache_entry['l1_edges'])\n                    l1_cache_loaded_ids.add(item_id)\n                    print(f'Loaded L1 for {item_id} from cache (source: {cache_entry.get('source', 'unknown')})')\n                except (json.JSONDecodeError, KeyError) as e:\n                    print(f'Error loading L1 cache for {item_id}: {e}')\n        print(f'Loaded {len(l1_cache_loaded_ids)} L1 items from cache')\n    G = build_graph(ai_items, calls_dict)\n    if use_llm_l1:\n        print('Applying LLM polish to L1...')\n        for item_id, item in ai_items.items():\n            if item_id not in l1_cache_loaded_ids:\n                raw_edges = calls_dict.get(item_id, [])\n                polished_edges = polish_l1_with_llm(item, raw_edges, api_url, model, dry_run=False, llm_raw=llm_raw)\n                item.l1_edges = polished_edges\n                time.sleep(1)\n        if save_cache:\n            l1_cache_new = {}\n            for item_id, item in ai_items.items():\n                if item.l1_edges:\n                    l1_cache_new[item_id] = {'l1_edges': json.dumps(item.l1_edges, ensure_ascii=False), 'type': item.type, 'file_path': item.file_path or __file__, 'source': 'LLM', 'timestamp': time.time()}\n            if l1_cache_new:\n                merge_l1_cache(l1_cache_new, str(l1_cache_path))\n                print(f'L1 cache updated: {len(l1_cache_new)} items (LLM).')\n            print(f'L1 stats: {stat_l1_cache(str(l1_cache_path))}')\n    elif save_cache:\n        l1_cache_new = {}\n        for item_id, item in ai_items.items():\n            if item.l1_edges and item_id not in l1_cache_loaded_ids:\n                l1_cache_new[item_id] = {'l1_edges': json.dumps(item.l1_edges, ensure_ascii=False), 'type': item.type, 'file_path': item.file_path or __file__, 'source': 'AST', 'timestamp': time.time()}\n        if l1_cache_new:\n            merge_l1_cache(l1_cache_new, str(l1_cache_path))\n            print(f'L1 cache updated: {len(l1_cache_new)} items (AST).')\n    l2_cache_loaded_ids = set()\n    if load_cache and l2_cache_path.exists():\n        print('Загрузка L2 кэша...')\n        l2_cache = load_l2_cache(str(l2_cache_path))\n        for item_id, item in ai_items.items():\n            if item_id in l2_cache:\n                cache_entry = l2_cache[item_id]\n                try:\n                    item.l2 = json.loads(cache_entry['l2'])\n                    l2_cache_loaded_ids.add(item_id)\n                    print(f'Loaded L2 for {item_id} from cache (source: {cache_entry.get('source', 'unknown')})')\n                except (json.JSONDecodeError, KeyError) as e:\n                    print(f'Error loading L2 cache for {item_id}: {e}')\n        print(f'Loaded {len(l2_cache_loaded_ids)} L2 items from cache')\n    l2_generator = L2Generator(api_url=api_url, model=model, dry_run=False, llm_raw=llm_raw)\n    items_to_generate = [item for item in ai_items.values() if item.l2 is None]\n    if items_to_generate:\n        print(f'Генерация L2 описаний для {len(items_to_generate)} элементов...')\n        l2_generator.generate_l2_batch(items_to_generate, batch_size=5)\n        if save_cache:\n            l2_cache_new = {}\n            for item in items_to_generate:\n                if item.l2:\n                    l2_cache_new[item.id] = {'l2': json.dumps(item.l2, ensure_ascii=False), 'type': item.type, 'file_path': item.file_path or __file__, 'source': 'LLM' if not l2_generator.dry_run else 'Fallback', 'timestamp': time.time()}\n            if l2_cache_new:\n                merge_l2_cache(l2_cache_new, str(l2_cache_path))\n                print(f'L2 cache updated: {len(l2_cache_new)} items.')\n            print(f'L2 stats: {stat_l2_cache(str(l2_cache_path))}')\n    else:\n        print('All L2 already loaded from cache.')\n    retriever = EmbedRetriever(pickle_path=str(embeddings_path))\n    retriever.add_items(ai_items, generator=l2_generator)\n    if save_cache:\n        l2_cache_fallback = {}\n        for item_id, item in ai_items.items():\n            if item.l2 and item_id not in l2_cache_loaded_ids and (item_id not in {it.id for it in items_to_generate}):\n                l2_cache_fallback[item_id] = {'l2': json.dumps(item.l2, ensure_ascii=False), 'type': item.type, 'file_path': item.file_path or __file__, 'source': 'Fallback', 'timestamp': time.time()}\n        if l2_cache_fallback:\n            merge_l2_cache(l2_cache_fallback, str(l2_cache_path))\n            print(f'L2 cache updated (fallback): {len(l2_cache_fallback)} items.')\n    print(f'Готово! Проиндексировано {len(ai_items)} элементов.')",
    "type": "function",
    "file_path": "C:\\ERV\\projects-ex\\kosmos-backend\\rag_engine.py",
    "source": "AST"
  }
}